{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQ97jTrjGkoBIUSEcPKP2X"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKaL0B8QcUqz"
      },
      "source": [
        "# Importing libaries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Lambda, Dropout, Flatten,Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import backend as K\n",
        "from keras import objectives\n",
        "from scipy.stats import norm\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lyC94SEccsj",
        "outputId": "f07ea197-08fb-431e-dd74-e054904555cd"
      },
      "source": [
        "# data load\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# x_train, x_test = x_train.astype('float32')/255., x_test.astype('float32')/255.\n",
        "# x_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1)\n",
        "print(x_train.shape, x_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ruu8GqiBICfY"
      },
      "source": [
        "class mnist_mlp():\n",
        "  def __init__(self,x_train,y_train,x_test,y_test, n_hidden, n_classes, batch_size, epoch, p=1):\n",
        "    self.x_train=x_train.copy()\n",
        "    self.x_test=x_test.copy()\n",
        "    self.y_train=y_train.copy()\n",
        "    self.y_test=y_test.copy()\n",
        "    self.n_hidden=n_hidden\n",
        "    self.n_classes=n_classes\n",
        "    self.batch=batch_size\n",
        "    self.n_epoch=epoch\n",
        "    self.reduction=p\n",
        "  \n",
        "  def preprocess(self):\n",
        "    #self.x_train = self.x_train.reshape(self.x_train.shape[0], self.x_train.shape[1]*self.x_train.shape[2])\n",
        "    #self.x_test = self.x_test.reshape(self.x_test.shape[0], self.x_test.shape[1]*self.x_test.shape[2])\n",
        "    self.x_train=self.x_train.reshape(self.x_train.shape[0],784)\n",
        "    self.x_test=self.x_test.reshape(self.x_test.shape[0],784)\n",
        "    self.x_train=self.x_train.astype('float32')/255\n",
        "    self.x_test=self.x_test.astype('float32')/255\n",
        "    self.y_train = np_utils.to_categorical(self.y_train, self.n_classes)\n",
        "    self.y_test = np_utils.to_categorical(self.y_test, self.n_classes) \n",
        "\n",
        "  def run(self):\n",
        "    mlp_model = Sequential()\n",
        "    mlp_model.add(Dense(self.n_hidden, activation='relu', input_dim=self.x_train.shape[1]))\n",
        "    mlp_model.add(Dropout(0.2))\n",
        "    mlp_model.add(Dense(self.n_hidden, activation='relu'))\n",
        "    mlp_model.add(Dropout(0.2))\n",
        "    mlp_model.add(Dense(self.n_hidden, activation='relu'))\n",
        "    mlp_model.add(Dropout(0.2))\n",
        "    mlp_model.add(Dense(self.n_classes, activation='softmax'))\n",
        "    mlp_model.summary()\n",
        "\n",
        "    #Compile Model\n",
        "    mlp_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Reduce Data Size\n",
        "    size = int(len(self.x_train) * self.reduction)\n",
        "    self.x_train, self.y_train = self.x_train[:size],self.y_train[:size]\n",
        "\n",
        "\n",
        "    #Fit Model  \n",
        "    mlp_model.fit(self.x_train, self.y_train, batch_size=self.batch, epochs=self.n_epoch, validation_split=0.33,shuffle=True,\n",
        "              callbacks= EarlyStopping(monitor='val_loss', patience=2, mode='min')\n",
        "             )\n",
        "    \n",
        "  def predict(self):\n",
        "    score = mlp_model.evaluate(self.x_test, self.y_test)\n",
        "    predictions = mlp_model.predict_classes(X_test)\n",
        "    predictions = list(predictions)\n",
        "    actuals = list(y_test)\n",
        "    print('Test accuracy: ', score[1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiJT08yzQ8Oj"
      },
      "source": [
        "MLP = mnist_mlp(x_train,y_train,x_test,y_test,128, 10, 32, 50,0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4phSIdwm0q7",
        "outputId": "fac74eef-5a58-4279-8134-2f4fbff69310"
      },
      "source": [
        "MLP.preprocess()\n",
        "MLP.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "503/503 [==============================] - 3s 4ms/step - loss: 0.9641 - accuracy: 0.6851 - val_loss: 0.2310 - val_accuracy: 0.9303\n",
            "Epoch 2/50\n",
            "503/503 [==============================] - 2s 3ms/step - loss: 0.2635 - accuracy: 0.9224 - val_loss: 0.1773 - val_accuracy: 0.9469\n",
            "Epoch 3/50\n",
            "503/503 [==============================] - 2s 3ms/step - loss: 0.1850 - accuracy: 0.9442 - val_loss: 0.1573 - val_accuracy: 0.9543\n",
            "Epoch 4/50\n",
            "503/503 [==============================] - 2s 3ms/step - loss: 0.1546 - accuracy: 0.9545 - val_loss: 0.1710 - val_accuracy: 0.9516\n",
            "Epoch 5/50\n",
            "503/503 [==============================] - 2s 3ms/step - loss: 0.1238 - accuracy: 0.9607 - val_loss: 0.1342 - val_accuracy: 0.9614\n",
            "Epoch 6/50\n",
            "503/503 [==============================] - 2s 3ms/step - loss: 0.1098 - accuracy: 0.9665 - val_loss: 0.1366 - val_accuracy: 0.9624\n",
            "Epoch 7/50\n",
            "503/503 [==============================] - 2s 3ms/step - loss: 0.0764 - accuracy: 0.9756 - val_loss: 0.1550 - val_accuracy: 0.9601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mV0MRwHJb5B"
      },
      "source": [
        "class mnist_CNN():\n",
        "  def __init__(self,x_train,y_train,x_test,y_test, n_classes, batch_size, epoch, p=1):\n",
        "    self.x_train=x_train.copy()\n",
        "    self.x_test=x_test.copy()\n",
        "    self.y_train=y_train.copy()\n",
        "    self.y_test=y_test.copy()\n",
        "    self.n_classes=n_classes\n",
        "    self.batch=batch_size\n",
        "    self.n_epoch=epoch\n",
        "    self.reduction=p\n",
        "  \n",
        "  def preprocess(self):\n",
        "    #self.x_train = self.x_train.reshape(self.x_train.shape[0], self.x_train.shape[1]*self.x_train.shape[2])\n",
        "    #self.x_test = self.x_test.reshape(self.x_test.shape[0], self.x_test.shape[1]*self.x_test.shape[2])\n",
        "    self.x_train=self.x_train.reshape(self.x_train.shape[0],28,28,1)\n",
        "    self.x_test=self.x_test.reshape(self.x_test.shape[0],28,28,1)\n",
        "    self.x_train=self.x_train.astype('float32')/255\n",
        "    self.x_test=self.x_test.astype('float32')/255\n",
        "    self.y_train = np_utils.to_categorical(self.y_train, self.n_classes)\n",
        "    self.y_test = np_utils.to_categorical(self.y_test, self.n_classes) \n",
        "  \n",
        "  def build_model(self):\n",
        "    self.m = Sequential()\n",
        "    self.m.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    BatchNormalization(axis=-1)\n",
        "    self.m.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    self.m.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    BatchNormalization(axis=-1)\n",
        "    self.m.add(Conv2D(64,(3, 3) ,activation='relu'))\n",
        "    BatchNormalization(axis=-1)\n",
        "    self.m.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    self.m.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    self.m.add(Flatten())\n",
        "    # Fully connected layer\n",
        "    BatchNormalization()\n",
        "    self.m.add(Dense(512,activation='relu'))\n",
        "    BatchNormalization()\n",
        "    self.m.add(Dropout(0.2))\n",
        "    self.m.add(Dense(self.n_classes, activation='softmax'))\n",
        "    self.m.summary()\n",
        "  \n",
        "  def run_model(self):\n",
        "    self.m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    self.m.fit(self.x_train, self.y_train, batch_size=self.batch, epochs=self.n_epoch, validation_split=0.33)\n",
        "              #callbacks=EarlyStopping(monitor='val_loss', patience=2, mode='min') )\n",
        "  \n",
        "  def predict(self):\n",
        "    score = self.m.evaluate(self.x_test, self.y_test)\n",
        "    predictions = self.m.predict_classes(self.x_test)\n",
        "    predictions = list(predictions)\n",
        "    actuals = list(y_test)\n",
        "    print('Test accuracy: ', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEj8YP5FPzlA",
        "outputId": "f83f01c9-0a5a-48a5-aaef-6424db6fbf96"
      },
      "source": [
        "cnn=mnist_CNN(x_train,y_train,x_test,y_test, 10, 32, 10, p=1)\n",
        "cnn.preprocess()\n",
        "cnn.build_model()\n",
        "cnn.run_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 594,922\n",
            "Trainable params: 594,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1257/1257 [==============================] - 37s 5ms/step - loss: 0.3220 - accuracy: 0.8977 - val_loss: 0.0639 - val_accuracy: 0.9802\n",
            "Epoch 2/10\n",
            "1257/1257 [==============================] - 6s 4ms/step - loss: 0.0464 - accuracy: 0.9856 - val_loss: 0.0504 - val_accuracy: 0.9841\n",
            "Epoch 3/10\n",
            "1257/1257 [==============================] - 6s 4ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0383 - val_accuracy: 0.9892\n",
            "Epoch 4/10\n",
            "1257/1257 [==============================] - 6s 4ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0437 - val_accuracy: 0.9895\n",
            "Epoch 5/10\n",
            "1257/1257 [==============================] - 5s 4ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0380 - val_accuracy: 0.9899\n",
            "Epoch 6/10\n",
            "1257/1257 [==============================] - 6s 4ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0356 - val_accuracy: 0.9897\n",
            "Epoch 7/10\n",
            "1257/1257 [==============================] - 6s 4ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0344 - val_accuracy: 0.9923\n",
            "Epoch 8/10\n",
            "1257/1257 [==============================] - 6s 4ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0469 - val_accuracy: 0.9899\n",
            "Epoch 9/10\n",
            "1257/1257 [==============================] - 6s 5ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0371 - val_accuracy: 0.9913\n",
            "Epoch 10/10\n",
            "1257/1257 [==============================] - 6s 4ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0625 - val_accuracy: 0.9855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xadfsdxKcfxu"
      },
      "source": [
        "class mnist_VAE():\n",
        "   def __init__(self,x_train, n_hidden, z_dim, batch_size, epoch):\n",
        "     self.x_train=x_train.copy()\n",
        "     self.n_hidden=n_hidden\n",
        "     self.z_dim=z_dim\n",
        "     self.batch=batch_size\n",
        "     self.n_epoch=epoch\n",
        "     self.vae_loss=0\n",
        "\n",
        "   def preprocess(self):\n",
        "     self.x_train=self.x_train.reshape(self.x_train.shape[0],784)\n",
        "     self.x_train=self.x_train.astype('float32')/255\n",
        "\n",
        "    \n",
        "   def encoder(self):\n",
        "     x = Input(shape=(self.x_train.shape[1:]))\n",
        "     x_encoded = Dense(self.n_hidden, activation='relu')(x)\n",
        "     x_encoded = Dense(self.n_hidden//2, activation='relu')(x_encoded)\n",
        "     mu = Dense(self.z_dim)(x_encoded)\n",
        "     log_var = Dense(self.z_dim)(x_encoded)\n",
        "     return x,mu,log_var\n",
        "\n",
        "   def sampling(self,args):\n",
        "     mu, log_var = args\n",
        "     eps = K.random_normal(shape=(self.z_dim,), mean=0., stddev=1.0)\n",
        "     return mu + K.exp(log_var) * eps\n",
        "     \n",
        "   def decoder(self, mu, log_var):\n",
        "     z_decoder1 = Dense(self.n_hidden//2, activation='relu')\n",
        "     z_decoder2 = Dense(self.n_hidden, activation='relu')\n",
        "     y_decoder = Dense(self.x_train.shape[1], activation='sigmoid')\n",
        "     z = Lambda(self.sampling, output_shape=(self.z_dim,))([mu, log_var])\n",
        "     z_decoded = z_decoder1(z)\n",
        "     z_decoded = z_decoder2(z_decoded)\n",
        "     y = y_decoder(z_decoded)  \n",
        "     return y \n",
        "\n",
        "   def loss(self,x,y,mu,log_var):\n",
        "     reconstruction_loss = objectives.binary_crossentropy(x, y) * x_train.shape[1]\n",
        "     kl_loss = 0.5 * K.sum(K.square(mu) + K.exp(log_var) - log_var - 1, axis = -1)\n",
        "     self.vae_loss = reconstruction_loss + kl_loss   \n",
        "\n",
        "   def build(self,x,y):\n",
        "     self.m = Model(x, y)\n",
        "     self.m.add_loss(self.vae_loss)\n",
        "     #self.m.summary()\n",
        "\n",
        "   def all_run(self):\n",
        "     x = Input(shape=(self.x_train.shape[1:]))\n",
        "     x_encoded = Dense(self.n_hidden, activation='relu')(x)\n",
        "     x_encoded = Dense(self.n_hidden//2, activation='relu')(x_encoded)\n",
        "     mu = Dense(self.z_dim)(x_encoded)\n",
        "     log_var = Dense(self.z_dim)(x_encoded)\n",
        "     z_decoder1 = Dense(self.n_hidden//2, activation='relu')\n",
        "     z_decoder2 = Dense(self.n_hidden, activation='relu')\n",
        "     y_decoder = Dense(self.x_train.shape[1], activation='sigmoid')\n",
        "     z = Lambda(self.sampling, output_shape=(self.z_dim,))([mu, log_var])\n",
        "     z_decoded = z_decoder1(z)\n",
        "     z_decoded = z_decoder2(z_decoded)\n",
        "     y = y_decoder(z_decoded)\n",
        "     reconstruction_loss = objectives.binary_crossentropy(x, y) * x_train.shape[1]\n",
        "     kl_loss = 0.5 * K.sum(K.square(mu) + K.exp(log_var) - log_var - 1, axis = -1)\n",
        "     vae_loss = reconstruction_loss + kl_loss \n",
        "     m = Model(x, y)\n",
        "     m.add_loss(vae_loss)\n",
        "     m.compile(optimizer='adam')\n",
        "     m.fit(self.x_train,\n",
        "       shuffle=True,\n",
        "       epochs=self.n_epoch,\n",
        "       batch_size=self.batch,\n",
        "       validation_split=0.3,\n",
        "       callbacks=EarlyStopping(monitor='val_loss', patience=2),\n",
        "       verbose=1)     \n",
        "\n",
        "   def run(self):\n",
        "     self.preprocess()\n",
        "     x,mu,log_var= self.encoder()\n",
        "     #self.sampling()\n",
        "     y=self.decoder(mu, log_var)\n",
        "     self.loss(x,y,mu,log_var)\n",
        "     self.build(x,y)\n",
        "     self.m.compile(optimizer='adam')\n",
        "     self.m.fit(self.x_train,\n",
        "       shuffle=True,\n",
        "       epochs=self.n_epoch,\n",
        "       batch_size=self.batch,\n",
        "       validation_split=0.3,\n",
        "       callbacks=EarlyStopping(monitor='val_loss', patience=2),\n",
        "       verbose=1)\n",
        "     \n",
        "   def build_encoder(self):\n",
        "     encoder = Model(x, mu)\n",
        "     encoder.summary()\n",
        "\n",
        "   def latent_rep(self, x_test):\n",
        "     z_latent = encoder.predict(x_test, batch_size=batch_size)\n",
        "     return z_latent\n",
        "\n",
        "   def build_decoder(self):\n",
        "     decoder_input = Input(shape=(self.z_dim,))\n",
        "     _z_decoded = z_decoder1(decoder_input)\n",
        "     _z_decoded = z_decoder2(_z_decoded)\n",
        "     _y = y_decoder(_z_decoded)\n",
        "     generator = Model(decoder_input, _y)\n",
        "     generator.summary()\n",
        "\n",
        "   def decode_digit(self):\n",
        "     x_decoded = generator.predict(z_sample)\n",
        "     digit = x_decoded[0].reshape(28, 28)\n",
        "     return digit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23GYnih6zJvn"
      },
      "source": [
        "vae = mnist_VAE(x_train, 256, 2, 64, 50)\n",
        "vae.preprocess()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK1uool3zfK5",
        "outputId": "4591d387-d59f-4a72-e97e-f972e76e7a1d"
      },
      "source": [
        "vae.all_run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reconstruction_loss: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='tf.math.multiply_16/Mul:0', description=\"created by layer 'tf.math.multiply_16'\") \t KL Loss: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='tf.math.multiply_17/Mul:0', description=\"created by layer 'tf.math.multiply_17'\")\n",
            "Epoch 1/50\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 9.2558 - val_loss: 7.3111\n",
            "Epoch 2/50\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 7.3316 - val_loss: 7.2891\n",
            "Epoch 3/50\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 7.2954 - val_loss: 7.2439\n",
            "Epoch 4/50\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 7.2693 - val_loss: 7.2185\n",
            "Epoch 5/50\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 7.2404 - val_loss: 7.1983\n",
            "Epoch 6/50\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 7.2369 - val_loss: 7.1974\n",
            "Epoch 7/50\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 7.2414 - val_loss: 7.3109\n",
            "Epoch 8/50\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 7.2539 - val_loss: 7.2514\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}